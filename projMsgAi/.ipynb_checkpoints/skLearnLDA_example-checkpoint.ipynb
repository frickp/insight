{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA example from\n",
    "http://scikit-learn.org/stable/auto_examples/applications/topics_extraction_with_nmf_lda.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### %load http://scikit-learn.org/stable/_downloads/topics_extraction_with_nmf_lda.py\n",
    "\"\"\"\n",
    "=======================================================================================\n",
    "Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation\n",
    "=======================================================================================\n",
    "\n",
    "This is an example of applying Non-negative Matrix Factorization\n",
    "and Latent Dirichlet Allocation on a corpus of documents and\n",
    "extract additive models of the topic structure of the corpus.\n",
    "The output is a list of topics, each represented as a list of terms\n",
    "(weights are not shown).\n",
    "\n",
    "The default parameters (n_samples / n_features / n_topics) should make\n",
    "the example runnable in a couple of tens of seconds. You can try to\n",
    "increase the dimensions of the problem, but be aware that the time\n",
    "complexity is polynomial in NMF. In LDA, the time complexity is\n",
    "proportional to (n_samples * iterations).\n",
    "\"\"\"\n",
    "\n",
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Lars Buitinck <L.J.Buitinck@uva.nl>\n",
    "#         Chyi-Kwei Yau <chyikwei.yau@gmail.com>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 10\n",
    "n_top_words = 20\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 2.612s.\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 2.897s.\n",
      "Extracting tf features for LDA...\n",
      "done in 2.792s.\n"
     ]
    }
   ],
   "source": [
    "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
    "# to filter out useless terms early on: the posts are stripped of headers,\n",
    "# footers and quoted replies, and common English words, words occurring in\n",
    "# only one document or in at least 95% of the documents are removed.\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "data_samples = dataset.data\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, #max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\n   I\\'m sorry, I thought we were discussing heresy.  I assumed that heresy\\nmeant a departure from orthodoxy, in which case generally accepted belief is\\nindeed an important issue.  In this case, the definition of the word \"create\"\\nis of great importance, since creation is the issue being discussed.\\n\\n\\n  I should have said \"given the Mormon belief.\"  If you disagree with the\\nMormon belief that creation is more a function of organization of eternally\\nexistent substance than one of ex nihilo creation, then that is the important\\npoint.\\n\\n\\n  Correction: you interpret the Bible to mean something very specific by\\nsuch terms.\\n\\n   It always cracks me up when anti-Mormons presume to tell Mormons what they\\nbelieve.  Mormons do, in fact, believe that all people, including Christ and\\nLucifer, are children of God in the sense that we were all created (or\\norganized or whatever) by Him.  We also believe that being \"offspring\" of\\nGod has a symbolic sense when applied to being spiritually \"born again\" of\\nHim.  Thus the same word can be used to convey different meanings.  This is\\nhow language works, Robert, and it\\'s why making someone an offender for a\\nword is dangerous.\\n\\n\\n<...>\\n\\n   On the contrary, Robert, it is not a red herring at all to show that those\\nwho rely wholly on the Bible cannot seem to agree on what it says.  You say\\nthat one must simply \"look at the Bible\" to see what it teaches, but centuries\\nof people doing just that have sho0wn that no one is really sure what it says.\\nAre we to believe that you are the only one who really understands the\\nscriptures?\\n\\n\\n  Let me clarify this one more time.  You did not refer to the Mormon belief\\nthat Jesus needed to be saved, but rather to McConkie\\'s belief in same.  We\\nkeep trying to point out to you that Bruce McConkie is not the source of\\nMormon doctrine, and you keep ignoring it. (see below)\\n\\n\\n  On the contrary, Robert, if you are quoting McConkie\\'s words as Mormon\\ncanon then the question of whether they are canon or not is of *great*\\nimportance.  The fact is that they are not.  Whether or not they indicate\\ngeneral Mormon belief would only be ascertainable by interviewing a large\\nnumber of Mormons.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()\n",
    "dataset['data'][19]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model with tf-idf features,n_samples=2000 and n_features=1000...\n",
      "done in 1.969s.\n",
      "\n",
      "Topics in NMF model:\n",
      "Topic #0:\n",
      "don just people think like know good time right ve say did make really way want going new year ll\n",
      "Topic #1:\n",
      "windows thanks file card does dos mail files know program use advance hi window help software looking ftp video pc\n",
      "Topic #2:\n",
      "drive scsi ide drives disk controller hard floppy bus hd cd boot mac cable card isa rom motherboard mb internal\n",
      "Topic #3:\n",
      "key chip encryption clipper keys escrow government algorithm security secure encrypted public nsa des enforcement law privacy bit use secret\n",
      "Topic #4:\n",
      "00 sale 50 shipping 20 10 price 15 new 25 30 dos offer condition 40 cover asking 75 01 interested\n",
      "Topic #5:\n",
      "armenian armenians turkish genocide armenia turks turkey soviet people muslim azerbaijan russian greek argic government serdar kurds population ottoman million\n",
      "Topic #6:\n",
      "god jesus bible christ faith believe christians christian heaven sin life hell church truth lord does say belief people existence\n",
      "Topic #7:\n",
      "mouse driver keyboard serial com1 port bus com3 irq button com sys microsoft ball problem modem adb drivers card com2\n",
      "Topic #8:\n",
      "space nasa shuttle launch station sci gov orbit moon earth lunar satellite program mission center cost research data solar mars\n",
      "Topic #9:\n",
      "msg food chinese flavor eat glutamate restaurant foods reaction taste restaurants salt effects carl brain people ingredients natural causes olney\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model with tf-idf features,\"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "exit()\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model:\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'hi'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicode('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-23741c3509b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m print(\"Fitting LDA models with tf features, n_samples=%d and n_features=%d...\"\n\u001b[0;32m----> 2\u001b[0;31m       % (n_samples, n_features))\n\u001b[0m\u001b[1;32m      3\u001b[0m lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n\u001b[1;32m      4\u001b[0m                                 \u001b[0mlearning_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'online'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 random_state=0)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_samples' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Fitting LDA models with tf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 2.640s.\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 3.075s.\n",
      "Extracting tf features for LDA...\n",
      "done in 2.818s.\n",
      "Fitting the NMF model with tf-idf features,n_samples=2000 and n_features=1000...\n",
      "done in 1.623s.\n",
      "\n",
      "Topics in NMF model:\n",
      "Topic #0:\n",
      "don just people think like know good time right ve say did make really way want going new year ll\n",
      "Topic #1:\n",
      "windows thanks file card does dos mail files know program use advance hi window help software looking ftp video pc\n",
      "Topic #2:\n",
      "drive scsi ide drives disk controller hard floppy bus hd cd boot mac cable card isa rom motherboard mb internal\n",
      "Topic #3:\n",
      "key chip encryption clipper keys escrow government algorithm security secure encrypted public nsa des enforcement law privacy bit use secret\n",
      "Topic #4:\n",
      "00 sale 50 shipping 20 10 price 15 new 25 30 dos offer condition 40 cover asking 75 01 interested\n",
      "Topic #5:\n",
      "armenian armenians turkish genocide armenia turks turkey soviet people muslim azerbaijan russian greek argic government serdar kurds population ottoman million\n",
      "Topic #6:\n",
      "god jesus bible christ faith believe christians christian heaven sin life hell church truth lord does say belief people existence\n",
      "Topic #7:\n",
      "mouse driver keyboard serial com1 port bus com3 irq button com sys microsoft ball problem modem adb drivers card com2\n",
      "Topic #8:\n",
      "space nasa shuttle launch station sci gov orbit moon earth lunar satellite program mission center cost research data solar mars\n",
      "Topic #9:\n",
      "msg food chinese flavor eat glutamate restaurant foods reaction taste restaurants salt effects carl brain people ingredients natural causes olney\n",
      "\n",
      "Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\n",
      "done in 25.942s.\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0:\n",
      "government people mr law gun state president states public use right rights national new control american security encryption health united\n",
      "Topic #1:\n",
      "drive card disk bit scsi use mac memory thanks pc does video hard speed apple problem used data monitor software\n",
      "Topic #2:\n",
      "said people armenian armenians turkish did saw went came women killed children turkey told dead didn left started greek war\n",
      "Topic #3:\n",
      "year good just time game car team years like think don got new play games ago did season better ll\n",
      "Topic #4:\n",
      "10 00 15 25 12 11 20 14 17 16 db 13 18 24 30 19 27 50 21 40\n",
      "Topic #5:\n",
      "windows window program version file dos use files available display server using application set edu motif package code ms software\n",
      "Topic #6:\n",
      "edu file space com information mail data send available program ftp email entry info list output nasa address anonymous internet\n",
      "Topic #7:\n",
      "ax max b8f g9v a86 pl 145 1d9 0t 34u 1t 3t giz bhj wm 2di 75u 2tm bxn 7ey\n",
      "Topic #8:\n",
      "god people jesus believe does say think israel christian true life jews did bible don just know world way church\n",
      "Topic #9:\n",
      "don know like just think ve want does use good people key time way make problem really work say need\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-83fd341e0ebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
